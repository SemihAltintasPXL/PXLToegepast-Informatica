{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. **Loading** Boston dataset\n",
    "2. Splitting into **train**- and **test**-set\n",
    "3. Creating a **model** and training it\n",
    "4. **Predicting** test set\n",
    "5. **Evaluating** the result\n",
    "6. Using **other models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explain how to make a regression analysis to predict features of our data. We will use a linear regression because the concept is easy to understand. The dataset we will use is the Boston-dataset from ScikitLearn.\n",
    "\n",
    "A regression analysis tries to fit a model to a certain dataset, just like classification did. However, classification tries to match a specific set of labels with the data. Regression allows us to predict continuous values, like numbers, even if we haven't seen an entry in the data with that number before.\n",
    "\n",
    "To start, we do some Python imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Boston dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset from the datasets module in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a \"data\" and a \"target\" element. The \"data\"-element contains the features. The \"target\"-element contains the values we want to predict for each row in the data.\n",
    "We can check the dimensions of these arrays to see how many rows and features there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Data is an \" + str(boston.data.shape) + \" array.\")\n",
    "print(\"Target is an \" + str(boston.target.shape) + \" array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the description of the dataset, to gain information about the data in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Boston-dataset contains information about houses in Boston. Every house has a number of features, like the number of rooms or the crime rate in the town. Our goal is to predict the house's price from these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting into train- and test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must prepare the data before we can use it in an algorithm. We must turn our data- and target-array into a train_X, train_y, test_X and test_y set. To do this, we will write a function that we can use througout the notebook. We could also use sklearn's function for this, like we did in the previous notebook. But to get a better understanding of what happens, we will do it ourselves.\n",
    "\n",
    "Write a function that:\n",
    "* Takes `data`, `target` and `splitsize=20` as parameters.\n",
    "* Splits the data into `X_train` and `X_test`.\n",
    "* Splits the target into `y_train` and `y_test`.\n",
    "\n",
    "Hint: In Python, you can select the last 5 elements from an array like this: `a[-5:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test():\n",
    "    # TODO: complete this function\n",
    "        \n",
    "    X_train = data[:,:] # currently, this selects all rows and all columns\n",
    "    X_test  =\n",
    "    \n",
    "    y_train = target[:] # currently, this selects all rows\n",
    "    y_test  = \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SOLUTION ###\n",
    "def split_train_test(data, target, splitsize=20):\n",
    "    X_train = data[:-splitsize:]\n",
    "    X_test  = data[-splitsize:]\n",
    "    \n",
    "    y_train = target[:-splitsize]\n",
    "    y_test  = target[-splitsize:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (486, 13), y_train shape: (486,)\n",
      "X_test  shape: (20, 13) , y_test  shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(boston.data, boston.target)\n",
    "print(\"X_train shape: {}, y_train shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test  shape: {} , y_test  shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call this function on the data and print the shape to confirm we split it the right way.\n",
    "\n",
    "The shapes should be `(486, 13)`, `(486,)`, `(20, 13)` and `(20,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(boston.data, boston.target)\n",
    "print(\"X_train shape: {}, y_train shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test  shape: {} , y_test  shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a model and training it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new model. For this, find the linear regression model in sklearn and call its constructor (without parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model =  # TODO: create empty model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still empty and doesn't know anything. Train (fit) it with our train-data, so that it learns things about our Boston-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: fit the train-data to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use our trained model to make predictions about the test-data. This means that for the given X_test values, we will ask the model what the y_values would be, based on our X_train and y_train combinations.\n",
    "\n",
    "In sklearn, the model has a function for this. Predict the y_test values with this function. We will store these values as y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred =  # TODO: predict y_pred from X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have y_test (the real values for X_test) and y_pred. We can print these values and compare them, to get an idea of how good the model predicted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "print(\"-\"*75)  # print a line\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is hard to look at the numbers and decide how good the model was. We will need some kind of metric to evaluate our prediction. There are a lot of metrics we can use, so let's define two that are useful for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) measures the average error in our predictions. Between each point and prediction, the error is measured. These errors can be positive or negative if the prediction is below or above the actual value, so we need to take the absolute value of the error. But as we want to punish grave mistakes harder, we also square the errors. Then the average is calculated over all these squared errors. The result is one number that can be compared across different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that:\n",
    "* Takes y_test en y_pred as parameters.\n",
    "* Calculates the mean squared error\n",
    "* Prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def print_mean_squared_error():\n",
    "    # TODO: complete this function\n",
    "    \n",
    "    mse = \n",
    "    \n",
    "    print(\"Mean squared error: {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the mean squared error for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer to 0.0 this value is, the better the model predicts the y_test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. $R^2$ score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric to calculate how well our model performed is the $R^2$ score. This metric is often used in linear regression. It calculates the variance of our y_pred from our y_test by taking the square of the correlation coefficient between y_pred and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that:\n",
    "* Takes y_test en y_pred as parameters.\n",
    "* Calculates the $R^2$ score.\n",
    "* Prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def print_r2_score():\n",
    "    # TODO: complete this function\n",
    "    \n",
    "    r2 = \n",
    "    \n",
    "    print(\"R2 score: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the $R^2$ score for our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this value is 1.0, our model made a perfect prediction of the true data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Visualising the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are easier to understand if we can visualise the data in some way.\n",
    "\n",
    "For this we write a function that visualises the actual and the predicted data. Because this function has little to do with machine learning and a lot more with Python's visualisation library Matplotlib, it is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise_features(X_test, y_test, y_pred, column=0):\n",
    "    # we can only visualise two dimensions, so if the data has more columns, select one\n",
    "    if len(X_test) > 1:\n",
    "        X_test = X_test[:, column]\n",
    "    \n",
    "    plt.scatter(X_test, y_test, color='blue', label='True data')\n",
    "    plt.scatter(X_test, y_pred, color='orange', label='Predicted')\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Labels\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to plot the data. To explain what we're seeing: the x-axis shows the X_test values of a certain column. The y-axis shows the y_test labels in blue and the y_pred labels in orange. So for every value on the x-axis, there will be two y-values. The orange dot should be as close to the blue dot as possible for us to have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualise_features(X_test, y_test, y_pred, column=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this plot, we see that the predicted values sometimes come close to the real ones, and sometimes they are completely different. What is important to notice is that our orange predicted dots all seem to follow one line (more or less). This is to be expected, as we used a linear model to predict our data. Linear models assume our data has a linear shape and try to find the best linear model for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction differs from our perfectly linear model however. The reason for this is simple: we used all the columns in the data to predict the final label. But when we visualised the data, we picked only one column for the X-axis. To demonstrate, let's train the model on just one column of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column = 12  # we'll only consider the data's 12th column\n",
    "X_train, y_train, X_test, y_test = split_train_test(boston.data[:, column:column+1], boston.target)\n",
    "model =   # TODO: fill this in with the model, as before\n",
    "          # TODO: train the model as before\n",
    "y_pred =  # TODO: predict y_pred as before\n",
    "visualise_features(X_test, y_test, y_pred, column=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see our prediction is perfectly linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn contains a lot of models. After turning our data into a train- and test-dataset, we can apply multiple models to it. Below is a list of model names. Try to find each of them in sklearn and call the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": ,  # TODO: fill in (don't forget the comma at the end)\n",
    "    \"Support Vector Machine (SVM)\": ,\n",
    "    \"Stochastic Gradient Descent (SGD) Regressor\": ,\n",
    "    \"Bayesian Ridge Regression\": ,\n",
    "    \"Lasso model with Least Angle Regression (Lars)\": ,\n",
    "    \"Automatic Relevance Determination (ARD) Regression\": ,\n",
    "    \"Passive Aggressive Regressor\": ,\n",
    "    \"Theil-Sen Regression\": \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this list of models and apply them all to our data. If we print the names and the scores, we can compare them and find the best model for our data.\n",
    "\n",
    "As before, train the model and predict the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(boston.data, boston.target)\n",
    "\n",
    "for modelName, model in models.items():  # iterate over all models\n",
    "    print(modelName)\n",
    "              # TODO: train the model as before\n",
    "    y_pred =  # TODO: predict y_pred as before\n",
    "    print_mean_squared_error(y_test, y_pred)\n",
    "    print_r2_score(y_test, y_pred)\n",
    "    print(\"-\"*75)  # print a line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the mean squared error should be closest to 0 and the $R^2$ score closest to 1. Did one of the other models perform better than the linear regression model we used first?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
